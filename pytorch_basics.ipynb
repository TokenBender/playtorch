{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# PyTorch Basics\n",
    "\n",
    "Welcome to the PyTorch Basics tutorial! In this notebook, we will cover the fundamental concepts of PyTorch, including tensor operations, basic neural network creation, and training. We will also explore how these concepts relate to matrix math and how lessons from NumPy can be leveraged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matrix-math-intuition",
   "metadata": {},
   "source": [
    "## Intuition Behind Matrix Math\n",
    "\n",
    "Matrix math is fundamental to deep learning and PyTorch. Tensors, which are multi-dimensional arrays, are the core data structure in PyTorch. Operations on tensors can be thought of as matrix operations, which are essential for understanding how neural networks process data.\n",
    "\n",
    "For example, a simple neural network layer can be represented as a matrix multiplication followed by a non-linear activation function. This operation transforms the input data into a new space, allowing the network to learn complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numpy-lessons",
   "metadata": {},
   "source": [
    "## Leveraging Lessons from NumPy\n",
    "\n",
    "NumPy is a powerful library for numerical computing in Python. Many of the concepts and operations in NumPy are directly applicable to PyTorch. For instance, creating arrays, performing element-wise operations, and reshaping arrays are all common tasks in both libraries.\n",
    "\n",
    "By understanding NumPy, you can quickly grasp the basics of PyTorch. The syntax and operations are very similar, making the transition smooth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tensor-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PyTorch\n",
    "import torch\n",
    "\n",
    "# Creating a tensor\n",
    "tensor = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(\"Tensor:\", tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tensor-operations",
   "metadata": {},
   "source": [
    "## Tensor Operations\n",
    "\n",
    "Let's perform some basic operations with tensors. These operations are analogous to matrix operations in linear algebra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tensor-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic operations with tensors\n",
    "tensor_add = tensor + tensor\n",
    "print(\"Addition:\", tensor_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tensor-multiplication",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_mul = tensor * tensor\n",
    "print(\"Multiplication:\", tensor_mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-tensor",
   "metadata": {},
   "source": [
    "## Creating Random Tensors\n",
    "\n",
    "We can also create tensors with random values. This is useful for initializing weights in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-tensor-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a random tensor\n",
    "random_tensor = torch.rand(2, 3)\n",
    "print(\"Random Tensor:\", random_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zeros-ones-tensor",
   "metadata": {},
   "source": [
    "## Tensors with Zeros and Ones\n",
    "\n",
    "We can create tensors with all elements set to zero or one. These are often used for initializing biases or creating masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zeros-tensor-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tensor with all elements set to zero\n",
    "zeros_tensor = torch.zeros(2, 3)\n",
    "print(\"Zeros Tensor:\", zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ones-tensor-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tensor with all elements set to one\n",
    "ones_tensor = torch.ones(2, 3)\n",
    "print(\"Ones Tensor:\", ones_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reshaping-tensor",
   "metadata": {},
   "source": [
    "## Reshaping Tensors\n",
    "\n",
    "We can reshape tensors to different dimensions. This is equivalent to changing the shape of a matrix in linear algebra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reshaping-tensor-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping a tensor\n",
    "reshaped_tensor = tensor.view(3, 1)\n",
    "print(\"Reshaped Tensor:\", reshaped_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mean-sum-tensor",
   "metadata": {},
   "source": [
    "## Computing Mean and Sum\n",
    "\n",
    "We can compute the mean and sum of tensor elements. These operations are analogous to those in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mean-value-computation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the mean of a tensor\n",
    "mean_value = tensor.mean()\n",
    "print(\"Mean Value:\", mean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sum-value-computation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the sum of a tensor\n",
    "sum_value = tensor.sum()\n",
    "print(\"Sum Value:\", sum_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-network",
   "metadata": {},
   "source": [
    "## Creating a Simple Neural Network\n",
    "\n",
    "Let's create a simple neural network using PyTorch. This network will perform a series of matrix multiplications and non-linear transformations to process the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-network-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 2)\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Creating an instance of the network\n",
    "net = SimpleNet()\n",
    "print(\"Network Architecture:\", net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-network",
   "metadata": {},
   "source": [
    "## Training the Network\n",
    "\n",
    "We will now train the network using a simple loss function and optimizer. This process involves iteratively updating the network's weights to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loss-function-optimizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Creating a loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# Training the network\n",
    "input_data = torch.tensor([1.0, 2.0, 3.0])\n",
    "target = torch.tensor([1.0])\n",
    "\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    output = net(input_data)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
